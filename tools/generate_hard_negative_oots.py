#!/usr/bin/env python3
"""
Script to generate "Hard Negative" OOT datasets (Pseudo-QA/Intent format).
Designed to mimic the structure of 'clinic150' and 'trec' to confuse the retriever.
"""

import os
import requests
import yaml
import logging
import random
import re

# ================= é…ç½®åŒºåŸŸ =================

# ç»å¯¹è·¯å¾„ï¼Œé˜²æ­¢å‡ºé”™
DATA_SAVE_DIR = "/root/autodl-tmp/MemoryAgentBench/data/oot_generated"
CONFIG_SAVE_DIR = "/root/autodl-tmp/MemoryAgentBench/configs/data_conf/Test_Time_Learning/OOT_Generated"
PROJECT_ROOT = "/root/autodl-tmp/MemoryAgentBench"

# éœ€è¦ç”Ÿæˆçš„æ•°é‡ (ä» 7 åˆ° 32)
START_INDEX = 7
END_INDEX = 32
TOTAL_NEEDED = END_INDEX - START_INDEX + 1

# æ¥æºï¼šå¤è…¾å ¡è®¡åˆ’å°è¯´
BOOK_URLS = [
    "https://www.gutenberg.org/files/2701/2701-0.txt",  # Moby Dick
    "https://www.gutenberg.org/files/135/135-0.txt",    # Les Miserables
    "https://www.gutenberg.org/files/84/84-0.txt",      # Frankenstein
]

# ä¼ªè£…æ ‡ç­¾ (ç”¨æ¥è¿·æƒ‘æ¨¡å‹)
# æˆ‘ä»¬ç”¨ä¸€äº›çœ‹èµ·æ¥åƒåˆ†ç±»çš„æ ‡ç­¾ï¼Œä½†å…¶å®æ˜¯éšæœºçš„
PSEUDO_LABELS = [
    "oot_negative", "irrelevant_class", "noise_data", "unknown_intent", 
    "general_query", "random_talk", "out_of_domain"
]

# æ¯ä¸ª OOT æ–‡ä»¶çš„ç›®æ ‡å¤§å° (å­—ç¬¦æ•°)
CHARS_PER_FILE = 1_500_000

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def download_corpus(urls):
    full_text = ""
    logging.info("ğŸš€ Starting corpus download...")
    for url in urls:
        try:
            logging.info(f"Downloading: {url}")
            resp = requests.get(url, timeout=30)
            if resp.status_code == 200:
                # ç®€å•çš„æ¸…æ´—ï¼Œå»æ‰æ˜æ˜¾çš„å¤´éƒ¨ç‰ˆæƒå£°æ˜
                text = resp.text
                if len(text) > 10000: text = text[5000:] 
                full_text += text + "\n"
            else:
                logging.warning(f"Failed to download {url}")
        except Exception as e:
            logging.error(f"Error downloading {url}: {e}")
    
    if not full_text:
        logging.warning("âš ï¸ Network failed. Using fallback text.")
        full_text = "This is a fallback text for OOT generation to prevent crash. " * 10000
        
    return full_text

def format_as_pseudo_qa(raw_text_slice):
    """
    æ ¸å¿ƒé€»è¾‘ï¼šæŠŠä¸€æ®µå°è¯´æ–‡æœ¬ï¼Œå¼ºè¡Œæ”¹æˆç±»ä¼¼ Clinic150 çš„æ ¼å¼ã€‚
    
    Clinic150 æ ¼å¼é€šå¸¸æ˜¯:
    [ç”¨æˆ·çš„è¯]
    label: [æ„å›¾åˆ†ç±»]
    """
    formatted_content = ""
    
    # 1. æŒ‰è¡Œæˆ–å¥å­åˆ†å‰²
    # è¿™é‡Œæˆ‘ä»¬ç®€å•æŒ‰æ¢è¡Œç¬¦åˆ†å‰²ï¼Œå¹¶è¿‡æ»¤æ‰å¤ªçŸ­çš„è¡Œ
    lines = raw_text_slice.split('\n')
    
    buffer = ""
    for line in lines:
        line = line.strip()
        if len(line) < 20: continue # è·³è¿‡ç©ºè¡Œå’ŒçŸ­å¥
        
        # 2. æ„é€ ä¼ªè£…æ ¼å¼
        # æˆ‘ä»¬å¯ä»¥æ¨¡ä»¿ main.py ä¸­çœ‹åˆ°çš„æ ¼å¼: "Question: ... label: ..."
        # ä¹Ÿå¯ä»¥æ¨¡ä»¿ Clinic çš„æ ¼å¼ã€‚ä¸ºäº†é€šç”¨æ€§ï¼Œæˆ‘ä»¬ç”¨ Question/Label ç»“æ„ã€‚
        
        fake_label = random.choice(PSEUDO_LABELS)
        
        # å…³é”®ï¼šè¿™é‡Œæ¨¡æ‹Ÿäº†ä½ è¦è·‘çš„æ•°æ®é›†çš„æ ¼å¼ï¼
        entry = f"Question: {line}\nlabel: {fake_label}\n\n"
        
        formatted_content += entry
        
    return formatted_content

def main():
    # 1. å‡†å¤‡ç›®å½•
    os.makedirs(DATA_SAVE_DIR, exist_ok=True)
    os.makedirs(CONFIG_SAVE_DIR, exist_ok=True)
    
    # 2. ä¸‹è½½è¯­æ–™
    corpus = download_corpus(BOOK_URLS)
    total_len = len(corpus)
    logging.info(f"Corpus ready: {total_len} chars")

    # 3. å¾ªç¯ç”Ÿæˆ
    for i in range(TOTAL_NEEDED):
        current_id = START_INDEX + i
        
        # å¾ªç¯åˆ‡ç‰‡
        start = (i * CHARS_PER_FILE) % total_len
        end = start + CHARS_PER_FILE
        if end > total_len:
            raw_slice = corpus[start:] + corpus[:end-total_len]
        else:
            raw_slice = corpus[start:end]
            
        # ğŸ”¥ æ ¸å¿ƒï¼šè½¬æ¢ä¸º QA æ ¼å¼
        qa_content = format_as_pseudo_qa(raw_slice)
        
        # å†™å…¥ TXT
        file_name = f"oot_gen_{current_id}.txt"
        file_path = os.path.join(DATA_SAVE_DIR, file_name)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(qa_content)
            
        # å†™å…¥ YAML (ä¸€æ¬¡æ€§è¡¥å…¨æ‰€æœ‰å­—æ®µ)
        config_name = f"OOT_Gen_{current_id}.yaml"
        config_path = os.path.join(CONFIG_SAVE_DIR, config_name)
        rel_path = os.path.relpath(file_path, PROJECT_ROOT)
        
        yaml_data = {
            "dataset": "Test_Time_Learning",
            "sub_dataset": "generated_oot_slice",
            "file_path": rel_path,
            "name": f"oot_generated_{current_id}",
            "format": "text",
            "seed": 42,
            "max_test_samples": 0,
            "split": "test",
            "description": f"Hard Negative OOT dataset #{current_id} (Pseudo-QA format)"
        }
        
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, default_flow_style=False, sort_keys=False)
            
        logging.info(f"âœ… Generated OOT #{current_id} (Pseudo-QA format)")

if __name__ == "__main__":
    main()
    